
# A1 - Data Manipulation, Data Visualization, and Data Preprocessing

![image](https://user-images.githubusercontent.com/8474647/105572271-21ab1c80-5d24-11eb-9088-ce16aff15eac.png)


In this assignment, we will practice several typical data manipulation techniques. 
You are not supposed to remmeber all the APIs. Even myself has to Google/StackOverflow all the time with my tiny brain.
But in a lot of cases, there are many different ways to do the same thing. 
The purpose of this assignment is for you to see a cleaner version of the API usage, and to understand several different data related concepts (by Googling).

Learning objective:
- Practice using Google.
- Practice reading/understanding API documentations, which has became a critical skill in Data Science. 

If you prefer having a book as reference:
- [Panda example references](https://riptutorial.com/Download/pandas.pdf) (some of the examples are not very clean)
- [A scikit-learn guide](http://www.smallake.kr/wp-content/uploads/2017/03/Mastering-Machine-Learning-with-scikit-learn.pdf)

Delivery:
- A step-by-step Jupyter notebook with your answers to the questions.

### Environment Setup

1. Open a Google Colab notebook or a Jupyter notebook on your laptop. If it is on your local machine, please also install pandas and scikit-learn by:
```
conda activate your_372_environment # this may be different depending on your system & assumes that you have created an environment
pip install pandas
pip install scikit-learn
pip install seaborn
```
2. In the first cell, run the code below to make sure everything is okay without any errors:

```python
import pandas
import sklearn
import seaborn
print(pandas.__version__)
print(sklearn.__version__)
print('alright I am done. this is too easy for me.')
```

Question: describe which option you use and what is your setup.

### Data Loading 

1. This is the link to our [csv file ](https://github.com/CISC-372/Assignments/releases/download/a1/train.csv)
2. Download the file and try to load it into a panda dataframe using its path. If you use Google Colab, you need to upload the file to the folder tree on the left. 
```python
import pandas as pd # we already did but usually people use pd as its abbreviation.
df = pd.read_csv(your_csv_file_path) # df usually is the abbreviation for `data frame` (like a table)
```
3. We can also load the file directly from url:
```python
import pandas as pd # we already did but usually people use pd as its abbreviation.
df = pd.read_csv('https://github.com/CISC-372/Assignments/releases/download/a1/train.csv')
```
4. Let's inspect some data.
```python
print(df)
```
5. Next, we will try out some APIs to explore the dataset (you may want to do it one-by-one). Describe what you see and what is your interepretation of each of them.
```python
df.describe() # run this in a seperate cell then the notebook will put the result into a nice table
print(list(df.columns))
print(df.columns[0])
print(df.describe())
```

### Data Manipulation

Try out the following commands, and describe what are your interpretations.

1. Select a/some column[s]:
```python
df.bathrooms
df.bathrooms.describe()
df[['bathrooms', 'bedrooms']]
df[['bathrooms', 'bedrooms', 'beds', 'guests_included']].describe()
```
2. Select a/some row[s]:
```python
df.iloc[1]
df.iloc[2]
df.iloc[2:10]
df.iloc[[1,3,4,9,19,45]]
df.iloc[[1,3,4,9,19,45]].describe()
```
5. Select some rows based on the condition:
```python
df.loc[df['beds'] > 3] 
df.loc[(df['bedrooms'] > 3) & (df['beds'] > 3)] 
df.loc[df['bedrooms'] > df['beds']]
df.loc[df['room_type'] == 'Private room'].describe()
df.loc[df['room_type'].isin(['Hotel room', 'Private room'])].describe()
```
6. Noted that every time we select the rows or part of the tables, actually we are creating a new variable. 
If you try:
```
df_beds = df.loc[df['beds'] > 3] 
print(df)
print(df_beds)
```
They are different. 

### Dataframe visualization:

Try out the following commands, and describe what are your interpretations. (you neeeeed to run commands one-by-one)
1. historgram:
```python
df.bathrooms.hist()
df.bedrooms.hist(bins=[0,1,2,3,4])
```
2. scatter (see relation):
```python
df.plot.scatter(x='guests_included',y='beds')
df.plot.scatter(x='bedrooms',
                      y='beds',
                      c='guests_included',
                      colormap='viridis')
```
3. Feature correlation
```python
import seaborn as sns
sns.heatmap(data=df[['bathrooms', 'bedrooms', 'beds', 'guests_included']].corr(), annot=True)
```
4. More hist:
```python
df[['bathrooms', 'bedrooms', 'beds', 'guests_included']].plot.hist(alpha=0.3, bins=[1,2,3,4,5,6]);
```

### Preprocessing:

Try out the following commands, and describe what are your interpretations. (you need to run commands one-by-one)
1. Missing value statistics:
```python
# Any missing values?
df.isnull().values.any()

# Total number of missing values
df.isnull().sum().sum()
```
2. Handle missing values:
```python
df_new = df.dropna()
df_new = df[df['beds'].notna()]
df_new = df[df['beds'].notna() & df['bedrooms'].notna()]

# noted that df is edited in-place here 
df['beds'].fillna((df['beds'].mean()), inplace=True)
```
3. Categorical encoding:
```python

# printing first-10 rows' room types 
print(list(df.room_type)[:10])

# encoding
encoded_room_type_columne = df.room_type.astype('category').cat.codes
print(list(encoded_room_type_columne)[:10])

# replace original:
df.room_type = encoded_room_type_columne
print(list(df.room_type)[:10])

```



